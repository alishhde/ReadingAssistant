# =============================================
# Reading Assistant Configuration Guide
# =============================================

# Hugging Face API Configuration
# ----------------------------
# Required for accessing Hugging Face models and endpoints (if using their models)
# Get your token from: https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Model Configuration
# ------------------
# Choose one of the following model types:
# 1. Local model: Runs on your machine
# 2. Remote model: Uses Hugging Face endpoint
# 3. OpenAI model: Uses OpenAI's API

# Local model configuration (required if using local models)
# Example: meta-llama/Llama-3.2-1B-Instruct
LOCAL_MODEL_NAME=your_local_model_name_here

# Remote model endpoint URL (required if using Hugging Face endpoints)
# Example: https://your-endpoint.huggingface.cloud
REMOTE_MODEL_NAME=your_remote_model_endpoint_here

# Embedding Model Configuration
# ---------------------------
# Model used for creating embeddings from text
# This is used for document processing and similarity search
# Example: sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_MODEL=your_embedding_model_name_here

# Model Type Selection
# -------------------
# Choose one of: "openai", "huggingface", or "local"
# This determines which model configuration to use
MODEL_TYPE=openai

# OpenAI Configuration
# -------------------
# Required if MODEL_TYPE is set to "openai"
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Environment Configuration
# -----------------------
# Set to "true" if running models locally on your machine
# Set to "false" if using remote models or OpenAI
RUNNING_LOCALLY=false

# Server Configuration
# -------------------
# Server hostname (e.g., 127.0.0.1 for localhost)
SERVER_NAME=127.0.0.1

# Server port number (e.g., 7860)
# Make sure this port is available on your system
SERVER_PORT=7860
