# =============================================
#     Reading Assistant Configuration Guide
# =============================================

# Model Type Selection
# -------------------
# Choose one of: "openai" or "ollama"
# This determines which model configuration to use
MODEL_TYPE=openai


# Model's Configurations
# ------------------
# 1. If MODEL_TYPE == Ollama:
# Set Model Name (Model needs to be already downloaded), e.g. llama3.1
LOCAL_MODEL_NAME=your_local_model_name_here

# 2. If MODEL_TYPE == OpenAI
# Set your OpenAI Key (https://platform.openai.com/api-keys)
OPENAI_API_KEY=your_openai_api_key_here

# RAG's Configurations
# -------------------
# Embedding Model Configuration
# Model used for creating embeddings from text
# This is used for document processing and similarity search
# e.g. sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_MODEL=your_embedding_model_name_here


# Server Configuration
# -------------------
# Server hostname (e.g., 127.0.0.1 for localhost)
SERVER_NAME=127.0.0.1

# Server port number (e.g., 7860)
# Make sure this port is available on your system
SERVER_PORT=7860


# Other Configurations
CONFIG_PATH=conf/configurations.yml
AGENT_MODEL_LOADER=true
AGENT_MAX_STEP=10
CHROMA_PATH=vectorbase/